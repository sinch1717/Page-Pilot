"""
LLM service using LangChain to generate static site files.
Supports switching between OpenAI (or AIpipe) and Anthropic providers.
"""
import os
import json
from typing import List, Dict
import logging
from langchain_openai import ChatOpenAI  # ✅ updated import for newer LangChain
from langchain_anthropic import ChatAnthropic
from langchain.schema import HumanMessage
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)


def get_llm():
    """
    Returns appropriate LLM based on LLM_PROVIDER environment variable.
    Defaults to OpenAI (or AIpipe) if not specified.
    """
    provider = os.getenv("LLM_PROVIDER", "openai").lower()

    if provider == "anthropic":
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY not set")
        logger.info("Using Anthropic Claude 3.5")
        return ChatAnthropic(
            model="claude-3-5-sonnet-20241022",
            anthropic_api_key=api_key
        )

    else:
        # ✅ Works for both OpenAI & AIpipe since AIpipe is OpenAI-compatible
        api_key = os.getenv("OPENAI_API_KEY")
        api_base = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
        if not api_key:
            raise ValueError("OPENAI_API_KEY not set")

        logger.info(f"Using OpenAI-compatible GPT model (Base: {api_base})")

        return ChatOpenAI(
            openai_api_key=api_key,
            openai_api_base=os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1"),
            model_name="gpt-4o-mini",
            temperature=0.7
        )
        print(llm.invoke("Say hello from AIpipe!").content)



async def generate_static_site(brief: str) -> List[Dict[str, str]]:
    """
    Uses LLM to generate a static site based on the brief.
    Returns: List of file dicts with 'path' and 'content' keys.
    """
    llm = get_llm()

    prompt = f"""Generate a complete, minimal static single-page web application based on this brief:

{brief}

Return ONLY a valid JSON object with this exact structure:
{{
  "files": [
    {{"path": "index.html", "content": "...full HTML content..."}},
    {{"path": "script.js", "content": "...full JavaScript content..."}},
    {{"path": "styles.css", "content": "...full CSS content..."}},
    {{"path": "README.md", "content": "...project README..."}}
  ]
}}

Requirements:
- Complete, working single-page application
- Include index.html, script.js, styles.css, README.md
- Visually appealing and functional
- Return ONLY the JSON (no explanations)

JSON:
"""

    logger.info("Calling LLM to generate site...")

    # ✅ Call LLM asynchronously
    message = HumanMessage(content=prompt)
    response = await llm.ainvoke([message])

    content = response.content.strip()

    # Handle code fences
    if content.startswith("```"):
        lines = content.split("\n")
        content = "\n".join(lines[1:-1]) if len(lines) > 2 else content
        content = content.replace("```json", "").replace("```", "").strip()

    try:
        result = json.loads(content)
        files = result.get("files", [])

        if not files:
            raise ValueError("No files generated by LLM")

        logger.info(f"✅ Successfully generated {len(files)} files")
        return files

    except json.JSONDecodeError as e:
        logger.error(f"❌ Failed to parse LLM response as JSON: {e}")
        logger.error(f"Response content: {content[:500]}")

        # Fallback minimal site
        logger.warning("⚠ Using fallback minimal site")
        return [
            {
                "path": "index.html",
                "content": f"""<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Generated Site</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div class="container">
    <h1>Generated Static Site</h1>
    <p>{brief}</p>
  </div>
</body>
</html>"""
            },
            {
                "path": "styles.css",
                "content": """body {
  font-family: Arial, sans-serif;
  background: #f4f4f4;
  color: #333;
  margin: 0;
  padding: 2rem;
}

.container {
  max-width: 800px;
  margin: auto;
  background: white;
  padding: 2rem;
  border-radius: 8px;
  box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}"""
            },
            {
                "path": "README.md",
                "content": f"""# Generated Static Site

## Brief
{brief}

## Files
- index.html
- styles.css

Auto-generated by AutoApp."""
            }
        ]
